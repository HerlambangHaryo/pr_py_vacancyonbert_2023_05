{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor library PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Mengimpor library HuggingFace Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Mengimpor library lainnya\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Mendefinisikan fungsi untuk melatih model\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, save_path):\n",
    "    # Mengatur device yang akan digunakan untuk melatih model, yaitu CPU atau GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Memindahkan model ke device yang telah ditentukan\n",
    "    model.to(device)\n",
    "\n",
    "    # Mengatur optimizer yang akan digunakan untuk mengoptimalkan bobot model, yaitu AdamW\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Mengatur scheduler yang akan digunakan untuk mengatur learning rate selama proses pelatihan, yaitu linear decay with warmup\n",
    "    # Scheduler ini akan membuat learning rate meningkat secara linear pada 10% epoch pertama (warmup), lalu menurun secara linear pada 90% epoch sisanya (decay)\n",
    "    total_steps = len(train_loader) * epochs # Jumlah total langkah yang akan dilakukan selama proses pelatihan\n",
    "    warmup_steps = int(total_steps * 0.1) # Jumlah langkah untuk fase warmup\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    # Mengatur loss function yang akan digunakan untuk menghitung seberapa besar kesalahan antara output model dan label sebenarnya, yaitu CrossEntropyLoss\n",
    "    # Loss function ini akan mengabaikan nilai -100 pada label_ids saat menghitung loss\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    # Membuat variabel untuk menyimpan nilai metric terbaik dan epoch terbaik selama proses pelatihan\n",
    "    best_metric = 0 # Nilai awal metric terbaik\n",
    "    best_epoch = 0 # Nilai awal epoch terbaik\n",
    "\n",
    "    # Melakukan iterasi pada setiap epoch\n",
    "    for epoch in range(epochs):\n",
    "        # Membuat list kosong untuk menyimpan nilai loss dan metric untuk setiap batch data pelatihan dan validasi\n",
    "        train_loss = []\n",
    "        train_metric = []\n",
    "        val_loss = []\n",
    "        val_metric = []\n",
    "\n",
    "        # Mengubah mode model menjadi mode train\n",
    "        model.train()\n",
    "\n",
    "        # Melakukan iterasi pada setiap batch data dalam train_loader\n",
    "        for batch in train_loader:\n",
    "            # Mengambil input_ids, attention_mask, dan label_ids dari batch data dan memindahkannya ke device yang telah ditentukan\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label_ids = batch[\"label_ids\"].to(device)\n",
    "\n",
    "            # Menghitung output dari model dengan menggunakan method forward dan input_ids, attention_mask, dan label_ids\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask, labels=label_ids)\n",
    "\n",
    "            # Mengambil logits dari output model\n",
    "            logits = output.logits\n",
    "\n",
    "            # Menghitung loss dari output dengan menggunakan loss function dan label_ids\n",
    "            loss = loss_function(logits.view(-1, model.config.num_labels), label_ids.view(-1))\n",
    "\n",
    "            # Menambahkan nilai loss ke list train_loss\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # Melakukan backpropagation dan optimis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
