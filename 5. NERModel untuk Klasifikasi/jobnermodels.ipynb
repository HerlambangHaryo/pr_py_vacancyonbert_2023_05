{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor library PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Mengimpor library HuggingFace Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "\n",
    "# Mendefinisikan kelas JobNERModel yang merupakan subclass dari kelas AutoModelForTokenClassification\n",
    "class JobNERModel(AutoModelForTokenClassification):\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        # Memanggil method __init__ dari superclass\n",
    "        super().__init__(AutoConfig.from_pretrained(model_name))\n",
    "\n",
    "        # Memuat model BERT dari model_name dengan menggunakan fungsi from_pretrained\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Menambahkan sebuah layer linear di atas model BERT untuk melakukan klasifikasi entitas\n",
    "        # Layer linear ini memiliki jumlah output yang sama dengan jumlah label entitas dalam data lowongan pekerjaan\n",
    "        # Kita dapat mengambil jumlah label entitas dari config.num_labels\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, self.config.num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, label_ids):\n",
    "        # Mengirimkan input_ids dan attention_mask ke model BERT dan mendapatkan output berupa last_hidden_state\n",
    "        last_hidden_state = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "\n",
    "        # Mengirimkan last_hidden_state ke layer linear dan mendapatkan output berupa logits\n",
    "        logits = self.classifier(last_hidden_state)\n",
    "\n",
    "        # Mengembalikan logits sebagai output\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
