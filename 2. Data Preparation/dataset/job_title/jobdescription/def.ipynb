{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download necessary resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Melakukan', 'pengelolaan', 'catatan', 'keuangan', 'baik', 'harian', ',', 'mingguan', ',', 'maupun', 'bulanan', '.', 'Melakukan', 'penjurnalan', 'dan', 'verifikasi', 'data', 'keuangan', '.', 'Memproses', 'pembayaran', 'melalui', 'Swiftnet', 'SAP', '.', 'Membuat', 'estimasi', 'cash', 'flow', 'harian', '.', 'Membuat', 'rekap', 'transaksi', '.', 'Mahir', 'menggunakan', 'program', 'SAP', '.', 'Kualifikasi', ':', 'Pendidikan', 'terakhir', 'S1', 'Akuntansi/Management', '.', 'Pengalaman', 'kerja', 'minimal', '1', 'tahun', 'di', 'bidang', 'yang', 'sama', '(', 'Diutamakan', 'Industri', 'Manufaktur', ')', '.', 'Mahir', 'menggunakan', 'aplikasi', 'Microsoft', 'Office', ';', 'terutama', 'Ms.', 'Excel', ',', 'menjadi', 'nilai', 'lebih', '.', 'Memiliki', 'integritas', 'tinggi', ',', 'percaya', 'diri', ',', 'komunikatif', ',', 'Inisiatif', 'dan', 'Pro-aktif', '.', 'Jujur', ',', 'disipilin', ',', 'teliti', ',', 'bertanggung', 'jawab', 'dan', 'mampu', 'bekerja', 'mandiri', 'maupun', 'dalam', 'tim', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Melakukan pengelolaan catatan keuangan baik harian, mingguan, maupun bulanan. Melakukan penjurnalan dan verifikasi data keuangan. Memproses pembayaran melalui Swiftnet SAP. Membuat estimasi cash flow harian. Membuat rekap transaksi. Mahir menggunakan program SAP. Kualifikasi :Pendidikan terakhir S1 Akuntansi/Management. Pengalaman kerja minimal 1 tahun di bidang yang sama (Diutamakan Industri Manufaktur). Mahir menggunakan aplikasi Microsoft Office ; terutama Ms. Excel, menjadi nilai lebih. Memiliki integritas tinggi, percaya diri, komunikatif, Inisiatif dan Pro-aktif. Jujur, disipilin, teliti, bertanggung jawab dan mampu bekerja mandiri maupun dalam tim.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: 92870\n",
      "yang: 83700\n",
      "the: 81617\n",
      "in: 81494\n",
      "of: 66112\n",
      "): 59389\n",
      "(: 59020\n",
      "-: 50952\n",
      "with: 48326\n",
      "dengan: 47173\n",
      "a: 41964\n",
      "di: 41938\n",
      "untuk: 38235\n",
      "&: 37459\n",
      "kerja: 37063\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import mysql.connector\n",
    "from nltk.tokenize import word_tokenize  # You may need to install NLTK and download resources\n",
    "\n",
    "# Sample text data (replace this with your actual data)\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "database = \"pr_scraping_job_vacancy_indonesia_2023_07\"\n",
    "mydb = mysql.connector.connect(host=host, user=user, password=\"\", database=database)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "query = \"SELECT name FROM jobdescription  \"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(query)\n",
    "data = mycursor.fetchall()\n",
    "\n",
    "# Initialize a word frequency dictionary\n",
    "word_freq = collections.Counter()\n",
    "\n",
    "# Tokenize and count word frequencies\n",
    "for row in data:\n",
    "    text = row[0]  # Extract the text from the first column of the row\n",
    "    tokens = word_tokenize(text)\n",
    "    word_freq.update(tokens)\n",
    "\n",
    "# # Print the most common words and their frequencies\n",
    "# most_common_words = word_freq.most_common(15)  # Change the number as needed\n",
    "# for word, freq in most_common_words:\n",
    "#     print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "di: 41938\n",
      "untuk: 38235\n",
      "&: 37459\n",
      "kerja: 37063\n",
      "for: 36731\n",
      "Memiliki: 31838\n",
      "tahun: 30207\n",
      "bekerja: 30204\n",
      "or: 24479\n",
      "dalam: 24024\n",
      "pengalaman: 23977\n",
      "baik: 23639\n",
      "minimal: 21028\n",
      "as: 20477\n",
      "experience: 19587\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words without any limit\n",
    "most_common_words = word_freq.most_common()\n",
    "\n",
    "# Define your limit and offset\n",
    "limit = 15  # Number of words you want to retrieve\n",
    "offset = 16  # Number of words to skip\n",
    "\n",
    "# Use slicing to get the desired subset of words\n",
    "subset_most_common_words = most_common_words[offset:offset+limit]\n",
    "\n",
    "# Print the subset of words and their frequencies\n",
    "for word, freq in subset_most_common_words:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import mysql.connector\n",
    "from nltk.tokenize import word_tokenize  # You may need to install NLTK and download resources\n",
    "from nltk.util import ngrams  # Import ngrams for creating bigrams\n",
    "\n",
    "# Sample text data (replace this with your actual data)\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "database = \"pr_scraping_job_vacancy_indonesia_2023_07\"\n",
    "mydb = mysql.connector.connect(host=host, user=user, password=\"\", database=database)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "query = \"SELECT name FROM jobdescription\"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(query)\n",
    "data = mycursor.fetchall()\n",
    "\n",
    "# Initialize a word frequency dictionary\n",
    "word_freq = collections.Counter()\n",
    "\n",
    "# Tokenize and create bigrams, then count word frequencies\n",
    "for row in data:\n",
    "    text = row[0]  # Extract the text from the first column of the row\n",
    "    tokens = word_tokenize(text)\n",
    "    bigrams = list(ngrams(tokens, 2))  # Create bigrams\n",
    "    word_freq.update(bigrams)  # Count bigram frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 'and'): 28092\n",
      "('.', 'Memiliki'): 21340\n",
      "(')', '.'): 21319\n",
      "('.', '-'): 14392\n",
      "(',', 'dan'): 13210\n",
      "('pengalaman', 'kerja'): 12082\n",
      "('untuk', 'posisi'): 11574\n",
      "('1', 'tahun'): 11444\n",
      "('posisi', 'ini'): 11278\n",
      "('yang', 'baik'): 11142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the most common bigrams and their frequencies\n",
    "most_common_bigrams = word_freq.most_common(10)  # Change the number as needed\n",
    "for bigram, freq in most_common_bigrams:\n",
    "    print(f\"{bigram}: {freq}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
